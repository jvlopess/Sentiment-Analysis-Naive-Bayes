{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/joao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/joao/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/joao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar as bibliotecas necessárias\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, f1_score, precision_score, recall_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# Baixar recursos necessários do nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregamento e Combinação de Múltiplos Arquivos CSV\n",
    "\n",
    "Aqui estamos realizando o carregamento e a combinação de múltiplos arquivos CSV que estão armazenados em um repositório no GitHub. Primeiramente, definimos a URL base e geramos uma lista com os nomes dos arquivos que desejamos carregar. Em seguida, criamos URLs completas para cada arquivo CSV.\n",
    "\n",
    "Utilizamos uma lista para armazenar os DataFrames individuais que são carregados ao fazer requisições HTTP GET para cada URL. Cada resposta é verificada para garantir que a requisição foi bem-sucedida antes de ler o conteúdo do CSV em um DataFrame. Se a requisição falhar, uma mensagem de erro é impressa.\n",
    "\n",
    "Após carregar todos os arquivos CSV, combinamos todos os DataFrames em um único DataFrame utilizando a função `concat` do pandas. Finalmente, exibimos as primeiras linhas do DataFrame combinado para verificar se os dados foram carregados corretamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = 'https://raw.githubusercontent.com/jvlopess/sentiment-analysis-naive-bayes/main/data/'\n",
    "file_names = [f'tweets_part_{i}.csv' for i in range(32)]\n",
    "urls = [base_url + file_name for file_name in file_names]\n",
    "\n",
    "# Lista para armazenar os DataFrames\n",
    "dataframes = []\n",
    "# Baixar e carregar cada arquivo CSV em um DataFrame\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        df = pd.read_csv(StringIO(response.text))\n",
    "        dataframes.append(df)\n",
    "    else:\n",
    "        print(f\"Failed to fetch {url}\")\n",
    "\n",
    "# Combinar todos os DataFrames em um único DataFrame\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Exibir as primeiras linhas do DataFrame combinado\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adição de Títulos de Colunas ao DataFrame\n",
    "\n",
    "Neste bloco de código, adicionamos títulos de colunas ao DataFrame `df`, uma vez que os dados carregados não possuem cabeçalhos definidos.\n",
    "\n",
    "Primeiro, definimos os títulos das colunas de acordo com a estrutura dos dados:\n",
    "- **label:** Indica a classificação do tweet (sentimento).\n",
    "- **time:** Hora em que o tweet foi postado.\n",
    "- **date:** Data em que o tweet foi postado.\n",
    "- **query:** Informação de consulta (geralmente vazia ou irrelevante).\n",
    "- **username:** Nome de usuário do autor do tweet.\n",
    "- **tweet:** O texto do tweet.\n",
    "\n",
    "Após definir os títulos das colunas, aplicamos essas definições ao DataFrame `df` e, em seguida, exibimos as primeiras linhas do DataFrame para verificar se os títulos foram aplicados corretamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        time                          date     query       username  \\\n",
       "0      0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1      0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2      0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3      0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4      0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                               tweet  \n",
       "0  is upset that he can't update his Facebook by ...  \n",
       "1  @Kenichan I dived many times for the ball. Man...  \n",
       "2    my whole body feels itchy and like its on fire   \n",
       "3  @nationwideclass no, it's not behaving at all....  \n",
       "4                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # As the data has no column titles, we will add our own\n",
    "df.columns = [\"label\", \"time\", \"date\", \"query\", \"username\", \"tweet\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embaralhamento e Redução do Conjunto de Dados\n",
    "\n",
    "Neste bloco de código, estamos embaralhando e reduzindo o tamanho do conjunto de dados para facilitar o processamento e a análise.\n",
    "\n",
    "1. **Embaralhamento do DataFrame:**\n",
    "   - Utilizamos `df.sample(frac=1)` para embaralhar as linhas do DataFrame `df` aleatoriamente. O parâmetro `frac=1` indica que todas as linhas devem ser incluídas no embaralhamento.\n",
    "\n",
    "2. **Redução do Tamanho do Conjunto de Dados:**\n",
    "   - Reduzimos o DataFrame para incluir apenas as primeiras 200.000 linhas utilizando `df = df[:200000]`. Isso é útil para trabalhar com um subconjunto gerenciável dos dados, especialmente em cenários onde o conjunto de dados original é muito grande.\n",
    "\n",
    "3. **Verificação da Estrutura do Conjunto de Dados:**\n",
    "   - Imprimimos a forma do DataFrame reduzido com `print(\"Dataset shape:\", df.shape)`, o que nos permite verificar o número de linhas e colunas após o embaralhamento e a redução.\n",
    "\n",
    "Essas etapas ajudam a garantir que o conjunto de dados seja aleatório e de um tamanho adequado para análises subsequentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (200000, 6)\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "df = df[:200000]\n",
    "print(\"Dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação dos Valores Únicos na Coluna de Rótulos\n",
    "\n",
    "Neste bloco de código, estamos verificando os valores únicos presentes na coluna `label` do DataFrame `df`.\n",
    "\n",
    "- **Objetivo:**\n",
    "  - O objetivo é identificar as diferentes classes ou rótulos presentes no conjunto de dados, que indicam a classificação do sentimento dos tweets.\n",
    "\n",
    "- **Método:**\n",
    "  - Utilizamos `df['label'].unique()` para extrair uma lista de valores únicos da coluna `label`.\n",
    "\n",
    "- **Importância:**\n",
    "  - Esta etapa é crucial para entender a distribuição dos dados e garantir que os rótulos de classificação sejam consistentes com as expectativas (por exemplo, 0 para sentimentos negativos e 4 para sentimentos positivos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Currently (0=negative,4=Positive) changing the notation to (0=Negative,1=Positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>533348</th>\n",
       "      <td>0</td>\n",
       "      <td>2197107207</td>\n",
       "      <td>Tue Jun 16 13:21:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>EddieHdz</td>\n",
       "      <td>In North Hollywood surviving  the flaming sun!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209109</th>\n",
       "      <td>0</td>\n",
       "      <td>1973889928</td>\n",
       "      <td>Sat May 30 12:01:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>PhoebeKaye11</td>\n",
       "      <td>ouch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445216</th>\n",
       "      <td>0</td>\n",
       "      <td>2068058373</td>\n",
       "      <td>Sun Jun 07 13:25:36 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SarFRENCH</td>\n",
       "      <td>this is insane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281673</th>\n",
       "      <td>1</td>\n",
       "      <td>2001760416</td>\n",
       "      <td>Tue Jun 02 01:59:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Saaaamie</td>\n",
       "      <td>another deal another day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492633</th>\n",
       "      <td>0</td>\n",
       "      <td>2184312398</td>\n",
       "      <td>Mon Jun 15 15:43:34 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>dubya_b</td>\n",
       "      <td>I no longer have an apartment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688840</th>\n",
       "      <td>0</td>\n",
       "      <td>2251620074</td>\n",
       "      <td>Sat Jun 20 04:04:37 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>franhaw</td>\n",
       "      <td>was not able to satisfy her hot pot craving to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799812</th>\n",
       "      <td>0</td>\n",
       "      <td>2329141278</td>\n",
       "      <td>Thu Jun 25 10:23:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Gigiborja</td>\n",
       "      <td>@juliejolie Maw is in brussels again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148593</th>\n",
       "      <td>0</td>\n",
       "      <td>1883179071</td>\n",
       "      <td>Fri May 22 08:08:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>thestolenfork</td>\n",
       "      <td>@TheRealRiquee We need to get together one day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170153</th>\n",
       "      <td>0</td>\n",
       "      <td>1962836388</td>\n",
       "      <td>Fri May 29 11:45:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>robertsm85</td>\n",
       "      <td>I have so much stuff in my car that I can just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621127</th>\n",
       "      <td>0</td>\n",
       "      <td>2228692866</td>\n",
       "      <td>Thu Jun 18 14:45:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Shona93</td>\n",
       "      <td>@chrisDevaney  You changed your background  Ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label        time                          date     query  \\\n",
       "533348       0  2197107207  Tue Jun 16 13:21:06 PDT 2009  NO_QUERY   \n",
       "209109       0  1973889928  Sat May 30 12:01:58 PDT 2009  NO_QUERY   \n",
       "445216       0  2068058373  Sun Jun 07 13:25:36 PDT 2009  NO_QUERY   \n",
       "1281673      1  2001760416  Tue Jun 02 01:59:05 PDT 2009  NO_QUERY   \n",
       "492633       0  2184312398  Mon Jun 15 15:43:34 PDT 2009  NO_QUERY   \n",
       "...        ...         ...                           ...       ...   \n",
       "688840       0  2251620074  Sat Jun 20 04:04:37 PDT 2009  NO_QUERY   \n",
       "799812       0  2329141278  Thu Jun 25 10:23:56 PDT 2009  NO_QUERY   \n",
       "148593       0  1883179071  Fri May 22 08:08:07 PDT 2009  NO_QUERY   \n",
       "170153       0  1962836388  Fri May 29 11:45:50 PDT 2009  NO_QUERY   \n",
       "621127       0  2228692866  Thu Jun 18 14:45:56 PDT 2009  NO_QUERY   \n",
       "\n",
       "              username                                              tweet  \n",
       "533348        EddieHdz  In North Hollywood surviving  the flaming sun!!!   \n",
       "209109    PhoebeKaye11                                             ouch    \n",
       "445216       SarFRENCH                                    this is insane   \n",
       "1281673       Saaaamie                          another deal another day   \n",
       "492633         dubya_b                    I no longer have an apartment.   \n",
       "...                ...                                                ...  \n",
       "688840         franhaw  was not able to satisfy her hot pot craving to...  \n",
       "799812       Gigiborja              @juliejolie Maw is in brussels again   \n",
       "148593   thestolenfork  @TheRealRiquee We need to get together one day...  \n",
       "170153      robertsm85  I have so much stuff in my car that I can just...  \n",
       "621127         Shona93  @chrisDevaney  You changed your background  Ha...  \n",
       "\n",
       "[200000 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']=df['label'].replace(4,1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção de Colunas Desnecessárias\n",
    "\n",
    "Neste bloco de código, estamos simplificando o DataFrame `df` removendo colunas que não são relevantes para a análise de sentimentos dos tweets.\n",
    "\n",
    "1. **Remoção de Colunas `date`, `query` e `username`:**\n",
    "   - Utilizamos `df.drop(['date', 'query', 'username'], axis=1, inplace=True)` para remover as colunas `date`, `query` e `username`. Estas colunas não são necessárias para a tarefa de classificação de sentimentos e são removidas para simplificar o DataFrame.\n",
    "\n",
    "2. **Remoção da Coluna `time`:**\n",
    "   - Removemos a coluna `time` separadamente utilizando `df.drop('time', axis=1, inplace=True)`, pois ela também não é relevante para a análise de sentimentos.\n",
    "\n",
    "3. **Exibição das Primeiras Linhas do DataFrame Modificado:**\n",
    "   - Utilizamos `df.head(10)` para exibir as primeiras 10 linhas do DataFrame após a remoção das colunas. Isso nos permite verificar que as colunas foram removidas corretamente e que o DataFrame agora contém apenas as colunas `label` e `tweet`.\n",
    "\n",
    "A remoção dessas colunas ajuda a focar apenas nos dados necessários para a análise, facilitando o processamento e a modelagem subsequentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>533348</th>\n",
       "      <td>0</td>\n",
       "      <td>In North Hollywood surviving  the flaming sun!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209109</th>\n",
       "      <td>0</td>\n",
       "      <td>ouch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445216</th>\n",
       "      <td>0</td>\n",
       "      <td>this is insane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281673</th>\n",
       "      <td>1</td>\n",
       "      <td>another deal another day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492633</th>\n",
       "      <td>0</td>\n",
       "      <td>I no longer have an apartment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465527</th>\n",
       "      <td>1</td>\n",
       "      <td>@iadiedee you're welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373198</th>\n",
       "      <td>0</td>\n",
       "      <td>Have to clean my house before the estate agent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863751</th>\n",
       "      <td>1</td>\n",
       "      <td>Pilates and yoga build strong core muscles to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64958</th>\n",
       "      <td>0</td>\n",
       "      <td>@modernsinglemom no, unfortunately they have t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757999</th>\n",
       "      <td>0</td>\n",
       "      <td>@jawilson thanks but I don't ever want to live...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                              tweet\n",
       "533348       0  In North Hollywood surviving  the flaming sun!!! \n",
       "209109       0                                             ouch  \n",
       "445216       0                                    this is insane \n",
       "1281673      1                          another deal another day \n",
       "492633       0                    I no longer have an apartment. \n",
       "1465527      1                          @iadiedee you're welcome \n",
       "373198       0  Have to clean my house before the estate agent...\n",
       "863751       1  Pilates and yoga build strong core muscles to ...\n",
       "64958        0  @modernsinglemom no, unfortunately they have t...\n",
       "757999       0  @jawilson thanks but I don't ever want to live..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['date','query','username'], axis=1, inplace=True)\n",
    "df.drop('time', axis=1, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para Limpeza dos Tweets\n",
    "\n",
    "Neste bloco de código, definimos a função `process_tweets` para realizar o pré-processamento dos textos dos tweets. Esta função aplica várias etapas de limpeza e transformação para preparar os dados para a análise de sentimentos.\n",
    "\n",
    "1. **Conversão para Minúsculas:**\n",
    "   - `tweet = tweet.lower()`\n",
    "   - Converte todo o texto do tweet para letras minúsculas, garantindo consistência e evitando duplicidades baseadas em diferenças de capitalização.\n",
    "\n",
    "2. **Remoção de URLs:**\n",
    "   - `tweet = re.sub(r'http\\S+|www.\\S+', '', tweet)`\n",
    "   - Remove quaisquer URLs presentes no tweet, pois elas geralmente não contribuem para a análise de sentimentos.\n",
    "\n",
    "3. **Remoção de Menções:**\n",
    "   - `tweet = re.sub(r'@\\w+', '', tweet)`\n",
    "   - Remove menções a outros usuários do Twitter, que começam com '@', para focar no conteúdo textual principal.\n",
    "\n",
    "4. **Remoção de Números:**\n",
    "   - `tweet = re.sub(r'\\d+', '', tweet)`\n",
    "   - Remove todos os números do tweet, pois geralmente não são úteis para a análise de sentimentos.\n",
    "\n",
    "5. **Remoção de Pontuações:**\n",
    "   - `tweet = tweet.translate(str.maketrans('', '', string.punctuation))`\n",
    "   - Remove todos os sinais de pontuação para simplificar o texto.\n",
    "\n",
    "6. **Tokenização:**\n",
    "   - `tokens = word_tokenize(tweet)`\n",
    "   - Divide o texto em tokens individuais (palavras), facilitando o processamento subsequente.\n",
    "\n",
    "7. **Remoção de Stop Words:**\n",
    "   - `tokens = [word for word in tokens if word not in stopwords.words('english')]`\n",
    "   - Remove stop words, que são palavras comuns (como \"and\", \"the\", etc.) que não adicionam significado relevante ao texto.\n",
    "\n",
    "8. **Lematização:**\n",
    "   - `lemmatizer = WordNetLemmatizer()`\n",
    "   - `tokens = [lemmatizer.lemmatize(word) for word in tokens]`\n",
    "   - Reduz as palavras às suas formas base ou raiz (por exemplo, \"running\" para \"run\"), ajudando a normalizar o texto.\n",
    "\n",
    "9. **Recomposição do Texto:**\n",
    "   - `return ' '.join(tokens)`\n",
    "   - Reúne os tokens processados em uma string única, representando o texto do tweet limpo e preparado para análise.\n",
    "\n",
    "Essa função de limpeza garante que os textos dos tweets estejam em um formato consistente e livre de ruídos, facilitando a análise e melhorando o desempenho dos modelos de aprendizado de máquina.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweets(tweet):\n",
    "    # Lower case\n",
    "    tweet = tweet.lower()\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+|www.\\S+', '', tweet)\n",
    "    # Remove mentions\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "    # Remove números\n",
    "    tweet = re.sub(r'\\d+', '', tweet)\n",
    "    # Remove pontuações\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenização\n",
    "    tokens = word_tokenize(tweet)\n",
    "    # Remover stop words\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Lematização\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação da Limpeza dos Tweets e Preparação dos Dados\n",
    "\n",
    "Neste bloco de código, aplicamos a função de limpeza aos tweets, realizamos a vetorização dos textos e preparamos os dados para treinamento e teste.\n",
    "\n",
    "1. **Aplicação da Função de Limpeza:**\n",
    "   - `df['tweet'] = df['tweet'].apply(process_tweets)`\n",
    "   - Aplica a função `process_tweets` a cada tweet na coluna `tweet` do DataFrame `df`. Isso transforma os tweets brutos em textos limpos e padronizados, prontos para a vetorização.\n",
    "\n",
    "2. **Vetorização usando CountVectorizer:**\n",
    "   - `vectorizer = CountVectorizer(max_features=5000)`\n",
    "   - `X = vectorizer.fit_transform(df['tweet'])`\n",
    "   - Utiliza `CountVectorizer` para converter os textos dos tweets em uma matriz de contagens de palavras. Limitamos o número de características (palavras) a 5000 para manter a complexidade gerenciável.\n",
    "   - `X` é a matriz de características resultante da vetorização.\n",
    "\n",
    "3. **Preparação das Variáveis Dependente e Independente:**\n",
    "   - `y = df['label']`\n",
    "   - Define `y` como a variável dependente contendo os rótulos (sentimentos) dos tweets.\n",
    "\n",
    "4. **Divisão do Conjunto de Dados:**\n",
    "   - `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)`\n",
    "   - Divide os dados em conjuntos de treinamento e teste. Utilizamos 80% dos dados para treinamento (`X_train`, `y_train`) e 20% para teste (`X_test`, `y_test`).\n",
    "   - O parâmetro `random_state=42` garante que a divisão dos dados seja reprodutível.\n",
    "\n",
    "Essas etapas preparam os dados textuais para serem utilizados em modelos de aprendizado de máquina, convertendo-os de texto cru para uma representação numérica que pode ser processada por algoritmos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a limpeza dos tweets\n",
    "df['tweet'] = df['tweet'].apply(process_tweets)\n",
    "\n",
    "# Vetorização usando CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['tweet'])\n",
    "y = df['label']\n",
    "\n",
    "# Dividir o conjunto de dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
